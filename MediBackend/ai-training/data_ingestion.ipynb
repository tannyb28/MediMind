{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest complete: 295 chunks stored in “.chromadb/”.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdfplumber import open as open_pdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import getpass\n",
    "\n",
    "# get openai api key from environment variable or prompt and if not set\n",
    "# if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "#     openai_api_key = \n",
    "#     os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# 1. extract & chunk\n",
    "pdf_dir = \"/Users/tanishbhowmick/Documents/Projects/MediMind/MediBackend/ai-training/data\"\n",
    "pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "all_text = \"\"\n",
    "for pdf_path in pdf_files:\n",
    "    with open_pdf(pdf_path) as pdf:\n",
    "        all_text += \"\\n\".join(page.extract_text() or \"\" for page in pdf.pages) + \"\\n\"\n",
    "\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_text(all_text)\n",
    "\n",
    "# 2. embed\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectors = embeddings.embed_documents(chunks)\n",
    "\n",
    "# 3. init Chroma with a persist directory\n",
    "client = chromadb.PersistentClient(path=\"../.chromadb\")\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"inceptive_data\",\n",
    "    metadata={\"source\": \"Inceptive Data\"}\n",
    ")\n",
    "\n",
    "# 4. add data\n",
    "ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
    "metadatas = [{\"chunk_index\": i} for i in range(len(chunks))]\n",
    "collection.add(\n",
    "    documents=chunks,\n",
    "    embeddings=vectors,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"Ingest complete: {collection.count()} chunks stored in “.chromadb/”.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8569acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=inceptive_data)]\n"
     ]
    }
   ],
   "source": [
    "print(client.list_collections())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef06f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
